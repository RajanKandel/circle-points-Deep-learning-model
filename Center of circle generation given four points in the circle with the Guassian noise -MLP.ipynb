{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the artificial dataset for points in the circle with the guassian noise\n",
    "<uo>\n",
    "    <li>Each training example consists of four features</li>\n",
    "    <li>Dataset consists of 1000 training example and 400 testing example</li>\n",
    "<uo>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a random points in the circle (with uniform distribution) given the x,y cordinates \n",
    "#of the center of circle and radius\n",
    "import random \n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "class pointInCircle:\n",
    "    def __init__(self):\n",
    "        self.r =random.uniform(0,101)\n",
    "        self.x =random.uniform(-50,50)\n",
    "        self.y =random.uniform(-50,50)\n",
    "            \n",
    "    def randPoint(self):  \n",
    "        '''generate three points in the circle with uniform distribution'''\n",
    "        self.r =random.uniform(0,101)\n",
    "        self.x =random.uniform(-50,50)\n",
    "        self.y =random.uniform(-50,50)\n",
    "        points1 = []\n",
    "        for i in range(0,3):\n",
    "            #theta\n",
    "            theta = random.uniform(0, 2*math.pi)\n",
    "            \n",
    "            point = (self.x+self.r*math.cos(theta), self.y+self.r*math.sin(theta))\n",
    "            points1+= point\n",
    "                 \n",
    "        return(points1)\n",
    "    \n",
    "    def guassianDistPoint(self):\n",
    "        points2 = normal(loc=0, scale=0.01, size=6)\n",
    "        return(points2.tolist())\n",
    "        \n",
    "    \n",
    "    def pointsForTraining(self):        \n",
    "        sum_list = [a + b for a, b in zip(self.randPoint(),self.guassianDistPoint())]\n",
    "        sum_list.append(self.x)\n",
    "        sum_list.append(self.y)\n",
    "        #print(self.r)\n",
    "        return(sum_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pointInCircle()\n",
    "#h.randPoint() \n",
    "#h.guassianDistPoint()\n",
    "#h.pointsForTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_list =[]\n",
    "for i in range (0,1000):\n",
    "    train_data_list.append(h.pointsForTraining())\n",
    "    \n",
    "test_data_list =[]\n",
    "for j in range(0,500):\n",
    "    test_data_list.append(h.pointsForTraining())\n",
    "    \n",
    "circles_train_df =pd.DataFrame(train_data_list, columns =['x1','y1','x2','y2','x3','y3','h','k'])\n",
    "circles_test_df =pd.DataFrame(test_data_list, columns =['x1','y1','x2','y2','x3','y3','h','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>h</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.430934</td>\n",
       "      <td>30.733895</td>\n",
       "      <td>-77.126350</td>\n",
       "      <td>-15.786952</td>\n",
       "      <td>-76.701716</td>\n",
       "      <td>-5.956575</td>\n",
       "      <td>-21.225583</td>\n",
       "      <td>-13.195204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.936926</td>\n",
       "      <td>-53.851305</td>\n",
       "      <td>11.827795</td>\n",
       "      <td>54.507020</td>\n",
       "      <td>-21.763430</td>\n",
       "      <td>-87.956855</td>\n",
       "      <td>-11.415140</td>\n",
       "      <td>-15.206539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.164833</td>\n",
       "      <td>-27.599211</td>\n",
       "      <td>20.288562</td>\n",
       "      <td>-28.864708</td>\n",
       "      <td>30.963821</td>\n",
       "      <td>-14.745253</td>\n",
       "      <td>26.257636</td>\n",
       "      <td>-22.279443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.810458</td>\n",
       "      <td>101.382642</td>\n",
       "      <td>117.088729</td>\n",
       "      <td>3.146200</td>\n",
       "      <td>-21.063583</td>\n",
       "      <td>3.093157</td>\n",
       "      <td>48.003058</td>\n",
       "      <td>34.490030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.272127</td>\n",
       "      <td>-32.154106</td>\n",
       "      <td>13.324060</td>\n",
       "      <td>-42.057040</td>\n",
       "      <td>48.574430</td>\n",
       "      <td>-38.998781</td>\n",
       "      <td>31.062973</td>\n",
       "      <td>-41.954341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-32.032771</td>\n",
       "      <td>27.045023</td>\n",
       "      <td>73.133862</td>\n",
       "      <td>-0.815737</td>\n",
       "      <td>-39.573457</td>\n",
       "      <td>16.135349</td>\n",
       "      <td>13.731087</td>\n",
       "      <td>-12.624096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-10.985880</td>\n",
       "      <td>-35.301665</td>\n",
       "      <td>69.237093</td>\n",
       "      <td>-46.056308</td>\n",
       "      <td>85.116937</td>\n",
       "      <td>110.696462</td>\n",
       "      <td>39.422157</td>\n",
       "      <td>36.148271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-7.655613</td>\n",
       "      <td>-77.872779</td>\n",
       "      <td>-3.482182</td>\n",
       "      <td>-81.509089</td>\n",
       "      <td>68.537381</td>\n",
       "      <td>56.210442</td>\n",
       "      <td>46.413748</td>\n",
       "      <td>-19.916594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-36.123782</td>\n",
       "      <td>-109.701017</td>\n",
       "      <td>28.982423</td>\n",
       "      <td>42.139996</td>\n",
       "      <td>59.582504</td>\n",
       "      <td>-0.632626</td>\n",
       "      <td>-21.336265</td>\n",
       "      <td>-26.177776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-130.347907</td>\n",
       "      <td>-46.954364</td>\n",
       "      <td>-97.814997</td>\n",
       "      <td>-111.650050</td>\n",
       "      <td>-96.181062</td>\n",
       "      <td>21.935935</td>\n",
       "      <td>-46.811516</td>\n",
       "      <td>-45.457026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1          y1          x2          y2         x3          y3  \\\n",
       "0     13.430934   30.733895  -77.126350  -15.786952 -76.701716   -5.956575   \n",
       "1    -73.936926  -53.851305   11.827795   54.507020 -21.763430  -87.956855   \n",
       "2     19.164833  -27.599211   20.288562  -28.864708  30.963821  -14.745253   \n",
       "3     83.810458  101.382642  117.088729    3.146200 -21.063583    3.093157   \n",
       "4     16.272127  -32.154106   13.324060  -42.057040  48.574430  -38.998781   \n",
       "..          ...         ...         ...         ...        ...         ...   \n",
       "995  -32.032771   27.045023   73.133862   -0.815737 -39.573457   16.135349   \n",
       "996  -10.985880  -35.301665   69.237093  -46.056308  85.116937  110.696462   \n",
       "997   -7.655613  -77.872779   -3.482182  -81.509089  68.537381   56.210442   \n",
       "998  -36.123782 -109.701017   28.982423   42.139996  59.582504   -0.632626   \n",
       "999 -130.347907  -46.954364  -97.814997 -111.650050 -96.181062   21.935935   \n",
       "\n",
       "             h          k  \n",
       "0   -21.225583 -13.195204  \n",
       "1   -11.415140 -15.206539  \n",
       "2    26.257636 -22.279443  \n",
       "3    48.003058  34.490030  \n",
       "4    31.062973 -41.954341  \n",
       "..         ...        ...  \n",
       "995  13.731087 -12.624096  \n",
       "996  39.422157  36.148271  \n",
       "997  46.413748 -19.916594  \n",
       "998 -21.336265 -26.177776  \n",
       "999 -46.811516 -45.457026  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#circles_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataframe to csv file\n",
    "circles_train_df.to_csv('circle_trainpoints.csv', index=False)\n",
    "circles_test_df.to_csv('circle_testpoints.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,trainpoints, testpoints):\n",
    "        circle_train_df = pd.read_csv(trainpoints)\n",
    "        circle_test_df = pd.read_csv(testpoints)\n",
    "        \n",
    "        self.circle_train_df = circle_train_df.iloc[:,:].values\n",
    "        self.circle_test_df = circle_test_df.iloc[:,:].values\n",
    "        \n",
    "        self.x_circle_train_df = circle_train_df.iloc[:,0:6].values\n",
    "        self.y_circle_train_df = circle_train_df.iloc[:,6:7].values\n",
    "        \n",
    "        self.x_circle_test_df = circle_test_df.iloc[:,0:6].values        \n",
    "        self.y_circle_test_df = circle_test_df.iloc[:,6:7].values\n",
    "        \n",
    "        self.x_tensor_circle_train_df = torch.tensor(self.x_circle_train_df,dtype=torch.float64) \n",
    "        self.y_tensor_circle_train_df = torch.tensor(self.y_circle_train_df,dtype=torch.float64) \n",
    "        \n",
    "        self.x_tensor_circle_test_df = torch.tensor(self.x_circle_test_df,dtype=torch.float64) \n",
    "        self.y_tensor_circle_test_df = torch.tensor(self.y_circle_test_df,dtype=torch.float64) \n",
    "                \n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.x_tensor_circle_train_df),len(self.y_tensor_circle_train_df), len(self.x_tensor_circle_test_df), len(self.y_tensor_circle_test_df)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_tensor_circle_train_df[idx],self.y_tensor_circle_train_df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=MyDataset('circle_trainpoints.csv','circle_testpoints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.circle_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,trainpoints):\n",
    "        circle_train_df = pd.read_csv(trainpoints)\n",
    "                \n",
    "        self.circle_train_df = circle_train_df.iloc[:,:].values\n",
    "                \n",
    "        self.x_circle_train_df = circle_train_df.iloc[:,0:6].values\n",
    "        self.y_circle_train_df = circle_train_df.iloc[:,6:7].values\n",
    "           \n",
    "        self.x_tensor_circle_train_df = torch.tensor(self.x_circle_train_df,dtype=torch.float64) \n",
    "        self.y_tensor_circle_train_df = torch.tensor(self.y_circle_train_df,dtype=torch.float64) \n",
    "                       \n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.x_tensor_circle_train_df),len(self.y_tensor_circle_train_df)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_tensor_circle_train_df[idx],self.y_tensor_circle_train_df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # The examples are read at random, in no particular order\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read and print the first small batch of data examples. The shape of the features in each minibatch tells us both the minibatch size and the number of input features. Likewise, our minibatch of labels will have a shape given by batch_size.\n",
    "\n",
    "As we run the iteration, we obtain distinct minibatches successively until the entire dataset has been exhausted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8625e+00, -5.1419e+00,  7.9984e+00, -9.2141e+00,  2.7517e+01,\n",
      "         -1.6105e+01],\n",
      "        [-1.4165e+01,  3.3678e+01,  2.2845e+01, -2.4712e+01,  7.4632e+00,\n",
      "          4.0767e+01],\n",
      "        [-8.0355e+01, -7.8178e+00, -9.0945e+01,  1.1943e+01, -4.5500e+01,\n",
      "          7.9316e+01],\n",
      "        [ 5.4045e+01,  1.0433e+02,  1.9281e+01, -3.9280e+01,  6.2468e+01,\n",
      "          9.4727e+01],\n",
      "        [ 1.1585e+02, -1.4834e+01,  8.9158e+01, -3.8648e+01,  7.8349e+01,\n",
      "         -4.4299e+01],\n",
      "        [-6.4453e+01, -4.8437e+01, -7.6416e+00,  1.2878e+02, -1.2078e+02,\n",
      "         -8.5806e-01],\n",
      "        [ 3.3205e+01, -2.6668e+01,  1.2166e+01, -1.0337e+02, -1.1282e+02,\n",
      "         -5.1406e+01],\n",
      "        [ 4.2510e+01,  2.3118e+01,  3.5260e+01,  1.0022e-01,  4.4472e+01,\n",
      "          1.6851e+01],\n",
      "        [ 9.4890e+00, -8.4415e+00,  1.7294e+01, -2.3422e+01,  1.2130e+01,\n",
      "         -2.6269e+01],\n",
      "        [-1.5476e+01, -4.1268e+01,  1.5845e+00, -2.6536e+01, -1.1994e+01,\n",
      "         -5.0764e+01]], dtype=torch.float64) \n",
      " tensor([[ 36.9413],\n",
      "        [  6.8962],\n",
      "        [-39.9785],\n",
      "        [ -6.2923],\n",
      "        [ 38.0248],\n",
      "        [-37.4964],\n",
      "        [-38.2414],\n",
      "        [ 27.8463],\n",
      "        [ 10.6290],\n",
      "        [ -0.6646]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "features = p.x_circle_train_df\n",
    "#features=  torch.from_numpy(features)\n",
    "labels = p.y_circle_train_df \n",
    "#labels = torch.from_numpy(labels)\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the model parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing weights by sampling random numbers from a normal distribution with mean 0 and a standard deviation of 0.01, and setting the bias to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(0, 0.01, size=(6,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "updating them until they fit our data sufficiently well. Each update requires taking the gradient of our loss function with respect to the parameters. Given this gradient, we can update each parameter in the direction that may reduce the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):  #@save\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  \n",
    "    \"\"\"Squared loss.\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  \n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "matmul(): argument 'other' (position 2) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-dea0e85f6fa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Minibatch loss in `X` and `y`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# gradient on `l` with respect to [`w`, `b`]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-b07603fe26ff>\u001b[0m in \u001b[0;36mlinreg\u001b[1;34m(X, w, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#@save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: matmul(): argument 'other' (position 2) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#automatic differentiation, to compute the gradient.\n",
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # Minibatch loss in `X` and `y`\n",
    "        # gradient on `l` with respect to [`w`, `b`]\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # Update parameters using their gradient\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
